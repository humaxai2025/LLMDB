# LLM DB ğŸ¤–

**The Ultimate Large Language Model Comparison Tool**

LLM DB is a comprehensive, user-friendly web application that helps developers, researchers, and AI enthusiasts compare and choose the right Large Language Model (LLM) for their needs. With 150 carefully curated production models from 39+ providers, you'll never struggle to find pricing, context windows, or API integration details again.

[![Made with â¤ï¸](https://img.shields.io/badge/Made%20with-%E2%9D%A4%EF%B8%8F-red)](https://github.com)
[![Next.js](https://img.shields.io/badge/Next.js-15-black)](https://nextjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5-blue)](https://www.typescriptlang.org/)
[![Tailwind CSS](https://img.shields.io/badge/Tailwind-3-38bdf8)](https://tailwindcss.com/)

---

## ğŸ¯ Why LLM DB?

Choosing the right LLM can be overwhelming. Different providers, different pricing models, varying context windows, and scattered documentation make it hard to make informed decisions. **LLM DB solves this by putting all the information you need in one place.**

### The Problem
- ğŸ¤¯ **Too many models**: OpenAI, Anthropic, Google, Meta, Mistral, and 39+ other providers
- ğŸ’° **Complex pricing**: Per-token costs, input vs output pricing, varying by provider
- ğŸ“Š **Hard to compare**: Context windows range from 4K to 2M tokens
- ğŸ” **Scattered info**: Official docs across dozens of websites
- ğŸ’» **Integration confusion**: Different SDKs, APIs, and authentication methods
- ğŸ”„ **Outdated information**: Models and pricing change frequently

### The Solution
LLM DB gives you:
- âœ… **Instant comparison** of 150 production models in a sortable table
- âœ… **Real-time cost calculator** to estimate your expenses
- âœ… **Quality scores** based on benchmark performance
- âœ… **Python code samples** ready to copy-paste for every model
- âœ… **Advanced filtering** by price, context size, provider, status, and more
- âœ… **Side-by-side comparison** of up to 4 models
- âœ… **API availability info** with endpoints, authentication, and rate limits
- âœ… **Status indicators** showing NEW, UPDATED, and DEPRECATED models

---

## âœ¨ Key Features

### ğŸ†• Phase 1: Practical Implementation Features
**NEW - Complete for all 150 models!**

#### Working Code Examples
- **1,200+ code samples** (8 per model)
- **Python examples**: Basic chat, streaming responses, function calling
- **JavaScript examples**: Async/await, streaming, error handling
- **cURL examples**: Basic requests, streaming
- **Syntax highlighting** with dark mode support
- **One-click copy** to clipboard
- **Illustrative examples** with clear disclaimers

#### Real-World Use Cases
- **600+ industry scenarios** (3-5 per model)
- **7 industry verticals**: Legal, Finance, Healthcare, E-commerce, Software, Education, Media
- **Metrics included**: Time saved, accuracy, cost per operation, ROI
- **Difficulty ratings**: Easy, Medium, Hard
- **Implementation details** and real results
- **Note**: Illustrative examples based on common use patterns

#### Limitations & Best Practices
- **Comprehensive guides** for all 150 models
- **6 categories**: Known issues, common failures, content policies, performance, best practices, workarounds
- **Provider-specific warnings**: Rate limits, authentication, regional restrictions
- **Universal limitations**: Hallucinations, knowledge cutoff, consistency
- **Expert tips**: Error handling, cost optimization, production deployment
- **Official docs references** for verification

### ğŸ“Š Comprehensive Model Database
- **150 production models** - carefully curated, no fake/placeholder models
- **39+ providers** including OpenAI, Anthropic, Google, Meta, xAI, DeepSeek, and more
- **100% API coverage** - every model includes complete API information
- **Status indicators** - NEW (2024-2025 releases), UPDATED (recent pricing changes), DEPRECATED
- Regular updates with latest models and pricing

### ğŸ” Advanced Search & Filtering
- **Multi-criteria search** - filter by provider, model type, capabilities, and features
- **Status filters** - find new models, recently updated pricing, or deprecated models
- **Quick filters** - cheapest, largest context, best value, your favorites
- **Real-time search** - instant results as you type
- **Smart sorting** - by price, context window, quality score, or release date

### ğŸ’° Cost Analysis Tools
- **Pricing per million tokens** for both input and output
- **Real-world cost examples** (1K tokens, 10K tokens, 100K tokens)
- **Cost calculator** to estimate your monthly expenses
- **Sort by price** to find the most economical option
- **Books capacity calculator** - understand context in terms of books (100K tokens each)

### ğŸ§  Smart Model Comparison
- **Side-by-side comparison** of up to 4 models simultaneously
- **Quality scores** calculated from MMLU and HumanEval benchmarks
- **Context window size** - see which models can handle long documents
- **Performance benchmarks** (MMLU, HumanEval, inference speed)
- **Best use cases** - recommended applications for each model
- **Visual comparison** - easily spot differences across models

### ğŸ’» Developer-Friendly Integration ğŸ†•
- **1,200+ code examples** - 8 per model (Python, JavaScript, cURL)
- **3 languages supported** - Python, JavaScript/Node.js, and cURL
- **Multiple use cases** - Basic requests, streaming, function calling, error handling
- **Copy-to-clipboard** - One-click code copying with syntax highlighting
- **Installation commands** - Ready pip/npm install commands
- **API integration examples** - Proper authentication for all providers
- **Dark mode code blocks** - Professional syntax highlighting

### ğŸŒ API Availability Information
- **Complete endpoint URLs** - ready to use in your code
- **Authentication methods** - API keys, tokens, OAuth details
- **Rate limits** - understand tier-based quotas and throttling
- **Regional availability** - know where each model is accessible
- **Official documentation links** - quick access to provider docs
- **100% coverage** - every model includes complete API information

### ğŸ¨ Beautiful User Interface
- **Collapsible sections** - only see what you need
- **Dark mode** support with automatic theme switching
- **Responsive design** - works perfectly on mobile, tablet, and desktop
- **Keyboard shortcuts** for power users
- **Favorites** - star your most-used models
- **Search & filter** - find models instantly

### ğŸ“± Enhanced Model Detail View
Click any model to see:
- **Status Badges** - NEW, UPDATED, or DEPRECATED indicators in header
- **Overview** - primary purpose, best use cases, key features
- **Pricing & Economics** - detailed cost breakdown with examples
- **Technical Specs** - context window, capacity, last updated
- **Performance Benchmarks** - MMLU, HumanEval, speed ratings
- **API Availability** - endpoints, authentication, rate limits, regional availability
- **Working Code Examples** ğŸ†• - Python, JavaScript, and cURL samples (8 per model = 1,200+ total)
- **Real-World Use Cases** ğŸ†• - Industry-specific examples with metrics (600+ scenarios)
- **Limitations & Best Practices** ğŸ†• - Known issues, gotchas, and expert tips
- **Tags** - quick identification of model capabilities

---

## ğŸš€ Quick Start

### For Users
Simply visit the live site and start exploring! No installation needed.

### For Developers

**Prerequisites:**
- Node.js 18+ installed
- npm or yarn package manager

**Installation:**

```bash
# Clone the repository
git clone <your-repo-url>
cd LLMDB

# Install dependencies
npm install

# Run development server
npm run dev

# Open http://localhost:3000
```

**Build for production:**

```bash
npm run build
npm start
```

---

## ğŸ“– How to Use

### 1ï¸âƒ£ Browse Models
- View the comprehensive table of all LLM models
- Sort by **name**, **provider**, **context window**, **price**, or **quality score**
- Use the search bar to find specific models
- **Status badges** show NEW, UPDATED, or DEPRECATED models directly in the table

### 2ï¸âƒ£ Advanced Search & Filter
- Click **"Advanced Search"** button for multi-criteria filtering:
  - **Providers** - filter by specific providers (OpenAI, Anthropic, Google, etc.)
  - **Model Types** - chat, completion, embedding, multimodal
  - **Capabilities** - vision, function calling, streaming, etc.
  - **Status** - find new models, recently updated pricing, or deprecated ones
  - **Features** - long context, reasoning, coding specialist, etc.
- Click **quick filter tabs** to view:
  - All models
  - Cheapest options
  - Large context models
  - Best value models
  - Your favorites
- **Star models** to add them to favorites
- **Select up to 4 models** to compare side-by-side

### 3ï¸âƒ£ View Details
- Click the **â„¹ï¸ info icon** or **View Details** button on any model
- See **status badges** (NEW/UPDATED/DEPRECATED) in the model header
- Explore organized, collapsible sections:
  - **Overview** - what the model is good for
  - **Pricing & Economics** - detailed cost breakdown
  - **Context & Performance** - technical specifications
  - **Best For** - recommended use cases
  - **Key Features** - unique capabilities
  - **API Integration** - endpoints, authentication, rate limits, docs
  - **Working Code Examples** ğŸ†• - Python, JavaScript, cURL (expand to see)
  - **Real-World Use Cases** ğŸ†• - Industry examples with metrics (expand to see)
  - **Limitations & Best Practices** ğŸ†• - Gotchas and expert tips (expand to see)
  - **Tags** - model capabilities
- **Copy code** with one click
- **Expand/collapse** sections for easier navigation

### 4ï¸âƒ£ Calculate Costs
- Click **"Calculator"** button
- Enter your expected token usage
- See estimated costs for your selected model

### 5ï¸âƒ£ Keyboard Shortcuts
Press **?** to see all keyboard shortcuts:
- `/` - Focus search
- `c` - Toggle calculator
- `?` - Show keyboard help

---

## ğŸ—ï¸ Tech Stack

| Technology | Purpose |
|------------|---------|
| **Next.js 15** | React framework with App Router |
| **TypeScript** | Type-safe development |
| **Tailwind CSS** | Utility-first styling |
| **Lucide React** | Beautiful icons |
| **Vercel** | Deployment platform |

---

## ğŸ¨ Features in Detail

### Cost Calculator
Estimate your monthly LLM costs based on:
- Expected monthly token usage
- Input/output token ratio
- Model pricing
- Real-time calculations

### Quality Scoring
We calculate quality scores using:
- **MMLU (Massive Multitask Language Understanding)** - 60% weight
- **HumanEval (Coding Capability)** - 40% weight
- Normalized to 0-10 scale
- Color-coded badges (green = excellent, blue = good, etc.)

### Code Examples (Phase 1)
Every model includes **8 working code samples**:

**Python (3 examples):**
- Basic Chat Completion - Simple request with system/user messages
- Streaming Response - Real-time output streaming
- Function Calling - Tool use and function invocation

**JavaScript (3 examples):**
- Basic Chat Completion - Async/await patterns
- Streaming Response - For-await streaming
- Error Handling - Production-ready error management

**cURL (2 examples):**
- Basic Request - Command-line testing
- Streaming Request - Server-sent events

All examples include:
- **Provider-specific SDKs** (OpenAI, Anthropic, Google, etc.)
- **Correct authentication** patterns
- **Working imports** and initialization
- **Syntax highlighting** with dark mode
- **Copy-to-clipboard** functionality

### Supported Providers
OpenAI â€¢ Anthropic â€¢ Google â€¢ Meta â€¢ Mistral â€¢ Cohere â€¢ AWS â€¢ Azure â€¢ xAI â€¢ DeepSeek â€¢ Perplexity â€¢ Together AI â€¢ Groq â€¢ Fireworks â€¢ Anyscale â€¢ Replicate â€¢ Alibaba â€¢ Baidu â€¢ Tencent â€¢ Zhipu â€¢ MiniMax â€¢ Moonshot â€¢ AI21 â€¢ Databricks â€¢ Nvidia â€¢ Reka â€¢ Hugging Face â€¢ Stability AI â€¢ Microsoft â€¢ Amazon â€¢ Intel â€¢ IBM â€¢ and many more...

---

## ğŸ› ï¸ Customization

### Adding New Models

Edit `app/data/llm-data.ts`:

```typescript
{
  id: "model-id",
  name: "Model Name",
  provider: "Provider Name",
  contextWindow: 128000,
  inputCostPer1M: 10.00,
  outputCostPer1M: 30.00,
  releaseDate: "2024-11-08",
  description: "Model description",
  strengths: ["Complex tasks", "Long documents", "High performance"],
  apiInfo: {
    endpoint: "https://api.provider.com/v1/chat/completions",
    authentication: "API Key (Bearer token)",
    rateLimits: "10,000 TPM on tier 1",
    regionalAvailability: "Global",
    documentation: "https://docs.provider.com/api"
  },
  status: {
    isNew: true,
    pricingUpdated: true,
    pricingUpdateDate: "2024-11-08"
  }
}
```

### Updating Pricing

Pricing is in `app/data/llm-data.ts`. Update `inputCostPer1M` and `outputCostPer1M` fields. When updating pricing, also update the status badge:

```typescript
status: {
  pricingUpdated: true,
  pricingUpdateDate: "2025-11-08"  // Today's date
}
```

### Styling

Customize in:
- `tailwind.config.ts` - Colors, spacing, fonts
- `app/globals.css` - Global styles and CSS variables

---

## ğŸ“¦ Project Structure

```
LLMDB/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ [modelId]/
â”‚   â”‚   â””â”€â”€ page.tsx                        # Model detail page
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ModelDetailsCard.tsx            # Enhanced model card with Phase 1 features
â”‚   â”‚   â”œâ”€â”€ Phase1Features.tsx              # ğŸ†• Code examples, use cases, limitations
â”‚   â”‚   â”œâ”€â”€ MobileModelCard.tsx             # Mobile-responsive card view
â”‚   â”‚   â”œâ”€â”€ AdvancedSearch.tsx              # Multi-criteria search & filtering
â”‚   â”‚   â””â”€â”€ EnhancedModelComparison.tsx     # Side-by-side model comparison (up to 4)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ llm-data.ts                     # All model data (150 models)
â”‚   â”‚   â”œâ”€â”€ phase1-data-generator.ts        # ğŸ†• Dynamic Phase 1 content generation
â”‚   â”‚   â””â”€â”€ enriched-models.ts              # ğŸ†• Models with Phase 1 features
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ features.ts                     # TypeScript types
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ modelRecommendations.ts         # Smart model suggestions
â”‚   â”œâ”€â”€ globals.css                         # Global styles
â”‚   â”œâ”€â”€ layout.tsx                          # Root layout
â”‚   â””â”€â”€ page.tsx                            # Main table view with mobile support
â”œâ”€â”€ components/                              # Additional components
â”œâ”€â”€ public/                                  # Static assets
â”œâ”€â”€ next.config.mjs                         # Next.js config
â”œâ”€â”€ tailwind.config.ts                      # Tailwind config
â””â”€â”€ package.json                            # Dependencies
```

---

## ğŸš€ Deployment

### Deploy to Vercel (Recommended)

**Option 1: Via GitHub**
1. Push code to GitHub
2. Visit [vercel.com](https://vercel.com)
3. Click "Import Project"
4. Select your repository
5. Click "Deploy"

**Option 2: Via CLI**
```bash
npm install -g vercel
vercel
```

### Deploy to Other Platforms
- **Netlify**: Connect GitHub repo and deploy
- **Railway**: Import from GitHub
- **Self-hosted**: Run `npm run build` and serve `.next` folder

---

## ğŸŒŸ Use Cases

### For Developers
- Compare API pricing before choosing a provider
- Get working Python code instantly
- Calculate monthly costs based on usage
- Find models with specific context windows

### For Researchers
- Compare benchmark scores across models
- Identify best models for specific tasks
- Track latest model releases
- Understand capability differences

### For Businesses
- Estimate LLM infrastructure costs
- Compare quality vs price trade-offs
- Find most cost-effective options
- Plan for scale with context window info

### For Students
- Learn about different LLM providers
- Understand pricing models
- Access Python integration examples
- Explore latest AI models

---

## ğŸ¯ Roadmap

### âœ… Recently Completed - Phase 1 Launch!
- [x] **Phase 1 Complete**: Working code examples, use cases, and limitations for ALL 150 models
- [x] **1,200+ Code Examples**: Python, JavaScript, and cURL samples
- [x] **600+ Use Cases**: Real-world industry scenarios with metrics
- [x] **150 Limitation Guides**: Comprehensive best practices and gotchas
- [x] **Mobile Responsive Design**: Perfect UX on all devices
- [x] **Collapsible Sections**: Clean, organized modal dialogs
- [x] API Availability Information (endpoints, auth, rate limits)
- [x] Model Status Indicators (NEW, UPDATED, DEPRECATED badges)
- [x] Advanced Search & Filtering (multi-criteria)
- [x] Enhanced Model Comparison (up to 4 models)
- [x] Database cleanup (150 curated production models)

### ğŸš§ In Progress
- [ ] Model performance visualizations
- [ ] Export comparison tables to CSV/JSON

### ğŸ“‹ Planned Features - Phase 2
- [ ] **Live Testing Playground**: Test models directly in-browser
- [ ] **User Reviews & Ratings**: Community-driven insights
- [ ] **Community Prompts Library**: Share and discover effective prompts
- [ ] **Smart Model Selector Wizard**: Answer questions to find perfect model
- [ ] **Real News Feed**: Latest model updates and changes
- [ ] API cost comparison charts
- [ ] Save custom comparisons to browser storage
- [ ] Email/webhook alerts for price changes
- [ ] Model changelog tracking
- [ ] Usage calculator with custom workloads
- [ ] Provider status monitoring

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** changes (`git commit -m 'Add some AmazingFeature'`)
4. **Push** to branch (`git push origin feature/AmazingFeature`)
5. **Open** a Pull Request

### Adding Models
Please ensure new models include:
- Accurate pricing from official sources
- Context window size
- Benchmark scores (if available)
- Proper provider attribution
- Release date
- **API information** (endpoint, authentication, rate limits, regional availability, documentation)
- **Status badges** (isNew for 2024-2025 releases, pricingUpdated with date)
- Model strengths and description
- Only **real production models** - no fake or placeholder entries

---

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

---

## ğŸ™ Acknowledgments

- **Pricing data** sourced from official provider documentation
- **Benchmark scores** from published research papers and official announcements
- **Icons** by [Lucide](https://lucide.dev/)
- **Framework** by [Next.js](https://nextjs.org/)
- **Styling** by [Tailwind CSS](https://tailwindcss.com/)

---

## ğŸ“§ Contact & Support

- **Issues**: [GitHub Issues](https://github.com/your-repo/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-repo/discussions)
- **Updates**: Follow for latest model additions

---

## âš ï¸ Disclaimer

**Pricing and Model Information**: Updated regularly but may not always reflect the latest changes. Please verify critical information with official provider documentation.

**Code Examples**: Provided for illustrative and educational purposes. Test thoroughly before using in production.

**Real-World Use Cases**: Illustrative examples based on common use patterns. Actual results may vary. Consult vendor documentation for verified case studies.

**Limitations & Best Practices**: General guidance based on common patterns. Always refer to official provider documentation for the most current information.

This tool is for informational purposes only.

---

Made with â¤ï¸ by Sriram Srinivasan

**Last Updated**: November 8, 2025

---

## ğŸ“Š Database Statistics

**Models & Coverage:**
- **150 production models** across 39 providers
- **100% API coverage** - every model has complete API information
- **122 NEW models** - released in 2024-2025
- **81 models** with recent pricing updates
- **Latest additions**: o1, o3-mini, Codestral, Gemini 2.0 Flash, DeepSeek V3, Gemma 2 9B/27B

**Phase 1 Content (NEW):**
- **1,200+ code examples** (8 per model Ã— 150 models)
- **600+ use case scenarios** (3-5 per model)
- **150 comprehensive limitation guides**
- **3 programming languages** supported (Python, JavaScript, cURL)
- **7 industry verticals** covered
