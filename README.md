# LLM DB ğŸ¤–

**The Ultimate Large Language Model Comparison Tool**

LLM DB is a comprehensive, user-friendly web application that helps developers, researchers, and AI enthusiasts compare and choose the right Large Language Model (LLM) for their needs. With over 300+ models from 40+ providers, you'll never struggle to find pricing, context windows, or API integration details again.

[![Made with â¤ï¸](https://img.shields.io/badge/Made%20with-%E2%9D%A4%EF%B8%8F-red)](https://github.com)
[![Next.js](https://img.shields.io/badge/Next.js-15-black)](https://nextjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5-blue)](https://www.typescriptlang.org/)
[![Tailwind CSS](https://img.shields.io/badge/Tailwind-3-38bdf8)](https://tailwindcss.com/)

---

## ğŸ¯ Why LLM DB?

Choosing the right LLM can be overwhelming. Different providers, different pricing models, varying context windows, and scattered documentation make it hard to make informed decisions. **LLM DB solves this by putting all the information you need in one place.**

### The Problem
- ğŸ¤¯ **Too many models**: OpenAI, Anthropic, Google, Meta, Mistral, and 40+ other providers
- ğŸ’° **Complex pricing**: Per-token costs, input vs output pricing, varying by provider
- ğŸ“Š **Hard to compare**: Context windows range from 4K to 2M tokens
- ğŸ” **Scattered info**: Official docs across dozens of websites
- ğŸ’» **Integration confusion**: Different SDKs, APIs, and authentication methods

### The Solution
LLM DB gives you:
- âœ… **Instant comparison** of 300+ models in a sortable table
- âœ… **Real-time cost calculator** to estimate your expenses
- âœ… **Quality scores** based on benchmark performance
- âœ… **Python code samples** ready to copy-paste for every model
- âœ… **Smart filtering** by price, context size, or provider
- âœ… **Side-by-side comparison** of multiple models

---

## âœ¨ Key Features

### ğŸ“Š Comprehensive Model Database
- **300+ models** from all major providers
- **40+ providers** including OpenAI, Anthropic, Google, Meta, xAI, DeepSeek, and more
- Regular updates with latest models and pricing

### ğŸ’° Cost Analysis Tools
- **Pricing per million tokens** for both input and output
- **Real-world cost examples** (1K tokens, 10K tokens, 100K tokens)
- **Cost calculator** to estimate your monthly expenses
- **Sort by price** to find the most economical option

### ğŸ§  Smart Model Comparison
- **Quality scores** calculated from MMLU and HumanEval benchmarks
- **Context window size** - see which models can handle long documents
- **Books capacity** - understand size in terms of books (100K tokens each)
- **Performance benchmarks** (MMLU, HumanEval, inference speed)
- **Best use cases** - recommended applications for each model

### ğŸ’» Developer-Friendly Integration
- **Python code samples** for EVERY model - no more searching docs!
- **Installation commands** - one-click copy of pip install
- **API integration examples** with proper authentication
- **Working code** for OpenAI, Anthropic, Google, Cohere, AWS, and 35+ other providers
- **Copy-to-clipboard** functionality

### ğŸ¨ Beautiful User Interface
- **Collapsible sections** - only see what you need
- **Dark mode** support with automatic theme switching
- **Responsive design** - works perfectly on mobile, tablet, and desktop
- **Keyboard shortcuts** for power users
- **Favorites** - star your most-used models
- **Search & filter** - find models instantly

### ğŸ“± Model Detail View
Click any model to see:
- **Overview** - primary purpose, best use cases, key features
- **Pricing & Economics** - detailed cost breakdown with examples
- **Technical Specs** - context window, capacity, last updated
- **Performance Benchmarks** - MMLU, HumanEval, speed ratings
- **Python Integration** - working code examples with installation
- **Tags** - quick identification of model capabilities

---

## ğŸš€ Quick Start

### For Users
Simply visit the live site and start exploring! No installation needed.

### For Developers

**Prerequisites:**
- Node.js 18+ installed
- npm or yarn package manager

**Installation:**

```bash
# Clone the repository
git clone <your-repo-url>
cd LLMDB

# Install dependencies
npm install

# Run development server
npm run dev

# Open http://localhost:3000
```

**Build for production:**

```bash
npm run build
npm start
```

---

## ğŸ“– How to Use

### 1ï¸âƒ£ Browse Models
- View the comprehensive table of all LLM models
- Sort by **name**, **provider**, **context window**, **price**, or **quality score**
- Use the search bar to find specific models

### 2ï¸âƒ£ Filter & Compare
- Click **filter tabs** to view:
  - All models
  - Cheapest options
  - Large context models
  - Best value models
  - Your favorites
- **Star models** to add them to favorites
- **Select multiple models** to compare side-by-side

### 3ï¸âƒ£ View Details
- Click the **â„¹ï¸ info icon** on any model
- Explore organized sections:
  - **Overview** - what the model is good for
  - **Pricing** - detailed cost breakdown
  - **Specs** - technical specifications
  - **Benchmarks** - performance scores
  - **Python Code** - ready-to-use integration examples
- **Copy code** with one click

### 4ï¸âƒ£ Calculate Costs
- Click **"Calculator"** button
- Enter your expected token usage
- See estimated costs for your selected model

### 5ï¸âƒ£ Keyboard Shortcuts
Press **?** to see all keyboard shortcuts:
- `/` - Focus search
- `c` - Toggle calculator
- `?` - Show keyboard help

---

## ğŸ—ï¸ Tech Stack

| Technology | Purpose |
|------------|---------|
| **Next.js 15** | React framework with App Router |
| **TypeScript** | Type-safe development |
| **Tailwind CSS** | Utility-first styling |
| **Lucide React** | Beautiful icons |
| **Vercel** | Deployment platform |

---

## ğŸ¨ Features in Detail

### Cost Calculator
Estimate your monthly LLM costs based on:
- Expected monthly token usage
- Input/output token ratio
- Model pricing
- Real-time calculations

### Quality Scoring
We calculate quality scores using:
- **MMLU (Massive Multitask Language Understanding)** - 60% weight
- **HumanEval (Coding Capability)** - 40% weight
- Normalized to 0-10 scale
- Color-coded badges (green = excellent, blue = good, etc.)

### Python Code Examples
Every model includes:
- **Provider-specific SDKs** (OpenAI, Anthropic, Google, etc.)
- **OpenAI-compatible APIs** (xAI, DeepSeek, Perplexity, Groq, etc.)
- **REST API examples** (for providers without SDKs)
- **Correct authentication** patterns
- **Working imports** and initialization

### Supported Providers
OpenAI â€¢ Anthropic â€¢ Google â€¢ Meta â€¢ Mistral â€¢ Cohere â€¢ AWS â€¢ Azure â€¢ xAI â€¢ DeepSeek â€¢ Perplexity â€¢ Together AI â€¢ Groq â€¢ Fireworks â€¢ Anyscale â€¢ Replicate â€¢ Alibaba â€¢ Baidu â€¢ Tencent â€¢ Zhipu â€¢ MiniMax â€¢ Moonshot â€¢ AI21 â€¢ Databricks â€¢ Nvidia â€¢ Reka â€¢ Hugging Face â€¢ Stability AI â€¢ Microsoft â€¢ Amazon â€¢ Intel â€¢ IBM â€¢ and many more...

---

## ğŸ› ï¸ Customization

### Adding New Models

Edit `app/data/llm-data.ts`:

```typescript
{
  id: "model-id",
  name: "Model Name",
  provider: "Provider Name",
  contextWindow: 128000,
  inputCostPer1M: 10.00,
  outputCostPer1M: 30.00,
  description: "Model description",
  released: "2024",
  tags: ["Latest", "Long Context"],
  bestFor: ["Complex tasks", "Long documents"],
  purpose: "Advanced AI applications",
  keyFeatures: ["128K context", "High performance"],
  benchmarks: {
    mmlu: 90.0,
    humanEval: 92.5,
    speed: "fast"
  }
}
```

### Updating Pricing

Pricing is in `app/data/llm-data.ts`. Update `inputCostPer1M` and `outputCostPer1M` fields.

### Styling

Customize in:
- `tailwind.config.ts` - Colors, spacing, fonts
- `app/globals.css` - Global styles and CSS variables

---

## ğŸ“¦ Project Structure

```
LLMDB/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ [modelId]/
â”‚   â”‚   â””â”€â”€ page.tsx              # Model detail page
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ ModelDetailsCard.tsx  # Redesigned model card
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ llm-data.ts           # All model data
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ features.ts           # TypeScript types
â”‚   â”œâ”€â”€ globals.css               # Global styles
â”‚   â”œâ”€â”€ layout.tsx                # Root layout
â”‚   â””â”€â”€ page.tsx                  # Main table view
â”œâ”€â”€ components/                    # Additional components
â”œâ”€â”€ public/                        # Static assets
â”œâ”€â”€ next.config.mjs               # Next.js config
â”œâ”€â”€ tailwind.config.ts            # Tailwind config
â””â”€â”€ package.json                  # Dependencies
```

---

## ğŸš€ Deployment

### Deploy to Vercel (Recommended)

**Option 1: Via GitHub**
1. Push code to GitHub
2. Visit [vercel.com](https://vercel.com)
3. Click "Import Project"
4. Select your repository
5. Click "Deploy"

**Option 2: Via CLI**
```bash
npm install -g vercel
vercel
```

### Deploy to Other Platforms
- **Netlify**: Connect GitHub repo and deploy
- **Railway**: Import from GitHub
- **Self-hosted**: Run `npm run build` and serve `.next` folder

---

## ğŸŒŸ Use Cases

### For Developers
- Compare API pricing before choosing a provider
- Get working Python code instantly
- Calculate monthly costs based on usage
- Find models with specific context windows

### For Researchers
- Compare benchmark scores across models
- Identify best models for specific tasks
- Track latest model releases
- Understand capability differences

### For Businesses
- Estimate LLM infrastructure costs
- Compare quality vs price trade-offs
- Find most cost-effective options
- Plan for scale with context window info

### For Students
- Learn about different LLM providers
- Understand pricing models
- Access Python integration examples
- Explore latest AI models

---

## ğŸ¯ Roadmap

- [ ] Add JavaScript/TypeScript code samples
- [ ] API cost comparison charts
- [ ] Model performance visualizations
- [ ] Export comparison tables
- [ ] Save custom comparisons
- [ ] Email price alerts for models
- [ ] Advanced filtering (by benchmark scores, release date)
- [ ] Model availability by region

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** changes (`git commit -m 'Add some AmazingFeature'`)
4. **Push** to branch (`git push origin feature/AmazingFeature`)
5. **Open** a Pull Request

### Adding Models
Please ensure new models include:
- Accurate pricing from official sources
- Context window size
- Benchmark scores (if available)
- Proper provider attribution
- Release date

---

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

---

## ğŸ™ Acknowledgments

- **Pricing data** sourced from official provider documentation
- **Benchmark scores** from published research papers and official announcements
- **Icons** by [Lucide](https://lucide.dev/)
- **Framework** by [Next.js](https://nextjs.org/)
- **Styling** by [Tailwind CSS](https://tailwindcss.com/)

---

## ğŸ“§ Contact & Support

- **Issues**: [GitHub Issues](https://github.com/your-repo/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-repo/discussions)
- **Updates**: Follow for latest model additions

---

## âš ï¸ Disclaimer

Pricing and model information is updated regularly but may not always reflect the latest changes. Please verify critical information with official provider documentation. This tool is for informational purposes only.

---

Made with â¤ï¸ by Sriram Srinivasan

**Last Updated**: November 2025
